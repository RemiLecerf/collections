operation,base_url,endpoint,summary,description,operationId
get,openeo,/,Information about the back-end,"Lists general information about the back-end, including which version and endpoints of the openEO API are supported. May also include billing information.",capabilities
get,openeo,/.well-known/openeo,Supported openEO versions,"Lists all implemented openEO versions supported by the	service provider. This endpoint is the Well-Known URI	(see [RFC 5785](https://www.rfc-editor.org/rfc/rfc5785.html)) for openEO.		This allows a client to easily identify the most recent openEO	implementation it supports. By default, a client SHOULD connect to the	most recent production-ready version it supports. If not available, the	most recent supported version of *all* versions SHOULD be connected to.	Clients MAY let users choose to connect to versions that are not	production-ready or outdated.	The most recent version is determined by comparing the version numbers	according to rules from [Semantic Versioning](https://semver.org/),	especially [ยง11](https://semver.org/#spec-item-11). Any pair of API	versions in this list MUST NOT be equal according to Semantic Versioning.		The Well-Known URI is the entry point for clients and users, so make	sure it is permanent and easy to use and remember. Clients MUST NOT	require the well-known path (`/.well-known/openeo`) in the URL that is	specified by a user to connect to the back-end.		For clients, the usual behavior SHOULD follow these steps:	1. The user provides a URI, which may consist of a scheme (protocol), 	   an authority (host, port) and a path.	2. The client parses the URI and appends `/.well-knwon/openeo` to the	   path. Make sure to correctly handle leading/trailing slashes.	3. Send a request to the new URI.	   A. On success: Detect the most suitable API instance/version (see above)	      and read the [capabilites](#tag/Capabilities/operation/capabilities)	      from there.	   B. On failure: Directly try to read the capabilities from the original URI	      given by the user.		**This URI MUST NOT be versioned as the other endpoints.**	If your API is available at `https://openeo.example/api/v1`, and	you instruct your API users to use `https://openeo.example` as connection URI, 	the Well-Known URI SHOULD be located at `https://openeo.example/.well-known/openeo`.	The Well-Known URI is usually directly located at the top-level, but it is not a	requirement. For example, `https://openeo.example/eo/.well-known/openeo` is also allowed.		Clients MAY get additional information (e.g. title or description) about	a back-end from the most recent version that has the `production` flag	set to `true`.",connect
get,openeo,/file_formats,Supported file formats,"Lists supported input and output file formats.	*Input* file formats specify which file a back-end can *read* from.	*Output* file formats specify which file a back-end can *write* to.		The response to this request is an object listing all available input	and output file formats separately with their parameters and additional	data. This endpoint does not include the supported secondary web	services.		**Note**: Format names and parameters MUST be fully aligned with the	GDAL codes if available, see [GDAL Raster	Formats](https://gdal.org/drivers/raster/index.html) and [OGR Vector	Formats](https://gdal.org/drivers/vector/index.html). It is OPTIONAL to	support all output format parameters supported by GDAL. Some file	formats not available through GDAL may be defined centrally for openEO.	Custom file formats or parameters MAY be defined.		The format descriptions must describe how the file formats relate to 	data cubes. Input file formats must describe how the files have to be	structured to be transformed into data cubes. Output file formats must	describe how the data cubes are stored at the back-end and how the 	resulting file structure looks like.		Back-ends MUST NOT support aliases, for example it is not allowed to	support `geotiff` instead of `gtiff`. Nevertheless, openEO Clients MAY	translate user input input for convenience (e.g. translate `geotiff` to	`gtiff`). Also, for a better user experience the back-end can specify a	`title`.		Format names MUST be accepted in a *case insensitive* manner throughout the API.",list-file-types
get,openeo,/conformance,Conformance classes this API implements,"Lists all conformance classes specified in various standards that the	implementation conforms to. Conformance classes are commonly used in	all OGC APIs and the STAC API specification. openEO adds relatively	broadly defined conformance classes, especially for the extensions.	Otherwise, the implemented functionality can usually be retrieved from	the [capabilties](#tag/Capabilities/operation/capabilities) in openEO.		The general openEO conformance class is `https://api.openeo.org/1.2.0`.	See the individual openEO API extensions for their conformance classes.		The conformance classes listed at this endpoint and listed in the 	corresponding `conformsTo` property in `GET /` MUST be equal.		More details:	- [STAC API](https://github.com/radiantearth/stac-api-spec), especially the conformance class ""STAC API - Collections""	- [OGC APIs](https://ogcapi.ogc.org/)",conformance
get,openeo,/collections,Basic metadata for all datasets,"Lists available collections with at least the required information.		It is **strongly RECOMMENDED** to keep the response size small by	omitting larger optional values from the objects in `collections` (e.g. the	`summaries` and `cube:dimensions` properties).	To get the full metadata for a collection clients MUST	request `GET /collections/{collection_id}`.		This endpoint is compatible with [STAC API 0.9.0 and later](https://stacspec.org) and	[OGC API - Features 1.0](http://docs.opengeospatial.org/is/17-069r3/17-069r3.html).	[STAC API extensions](https://stac-api-extensions.github.io) and	[STAC extensions](https://stac-extensions.github.io)	can be implemented in addition to what is documented here.		Note: Although it is possible to request public collections without	authorization, it is RECOMMENDED that clients (re-)request the collections	with the Bearer token once available to also retrieve any private collections.",list-collections
get,openeo,/collections/{collection_id},Full metadata for a specific dataset,Lists **all** information about a specific collection specified by the	identifier `collection_id`.		This endpoint is compatible with [STAC API 0.9.0 and later](https://stacspec.org) and	[OGC API - Features 1.0](http://docs.opengeospatial.org/is/17-069r3/17-069r3.html).	[STAC API extensions](https://stac-api-extensions.github.io) and	[STAC extensions](https://stac-extensions.github.io)	can be implemented in addition to what is documented here.		Note: Providing the Bearer token is REQUIRED for private collections.,describe-collection
get,openeo,/collections/{collection_id}/queryables,Metadata filters for a specific dataset,"Lists **all** supported metadata filters (also called ""queryables"") for	a specific collection.		This endpoint is compatible with endpoint defined in the STAC API extension	[`filter`](https://github.com/stac-api-extensions/filter#queryables) and	[OGC API - Features - Part 3: Filtering](https://github.com/opengeospatial/ogcapi-features/tree/master/extensions/filtering).	For a precise definition please follow those specifications.		This endpoints provides a JSON Schema for each queryable that openEO	users can use in multiple scenarios:	1. For loading data from the collection, e.g. in the process `load_collection`.	2. For filtering items using CQL2 on the `/collections/{collection_id}/items` endpoint	   (if [STAC API - Features is implemented in addition to the openEO API](#tag/EO-Data-Discovery/STAC)).		Note: Providing the Bearer token is REQUIRED for private collections.",list-collection-queryables
get,openeo,/processes,Supported predefined processes,"Lists all predefined processes and returns detailed process descriptions, including parameters and return values.",list-processes
get,openeo,/udf_runtimes,Supported UDF runtimes,"Lists the supported runtimes for user-defined functions (UDFs), which includes either the programming languages including version numbers and available libraries including version numbers or docker containers.",list-udf-runtimes
get,openeo,/credentials/oidc,OpenID Connect authentication,"Lists the supported [OpenID Connect](http://openid.net/connect/)	providers (OP). OpenID Connect Providers MUST support [OpenID Connect	Discovery](http://openid.net/specs/openid-connect-discovery-1_0.html).		It is highly RECOMMENDED to implement OpenID Connect for public services	in favor of Basic authentication.		openEO clients MUST use the **access token** as part of the Bearer token	for authorization in subsequent API calls (see also the information	about Bearer tokens in this document). Clients MUST NOT use the id token	or the authorization code. The access token provided by an OpenID Connect	Provider does not necessarily provide information about the issuer (i.e. the	OpenID Connect provider) and therefore a prefix MUST be added to the Bearer	Token sent in subsequent API calls to protected endpoints. The Bearer	Token sent to protected endpoints MUST consist of the authentication	method (here `oidc`), the provider ID and the access token itself. All	separated by a forward slash `/`. The provider ID corresponds to the	value specified for `id` for each provider in the response body of this	endpoint.  The header in subsequent API calls for a provider with `id`	`ms` would look as follows: `Authorization: Bearer oidc/ms/TOKEN`	(replace `TOKEN` with the actual access token received from the OpenID	Connect Provider).		Back-ends MAY request user information ([including Claims](https://openid.net/specs/openid-connect-core-1_0.html#Claims))	from the [OpenID Connect Userinfo endpoint](https://openid.net/specs/openid-connect-core-1_0.html#UserInfo)	using the access token (without the prefix described above). Therefore,	both openEO client and openEO back-end are relying parties (clients) to	the OpenID Connect Provider.",authenticate-oidc
get,openeo,/credentials/basic,HTTP Basic authentication,"Checks the credentials provided through [HTTP Basic Authentication according to RFC 7617](https://www.rfc-editor.org/rfc/rfc7617.html) and returns an access token for valid credentials.		The credentials (username and password) MUST be sent in the HTTP header `Authorization` with type `Basic` and the Base64 encoded string consisting of username and password separated by a double colon `:`. The header would look as follows for username `user` and password `pw`: `Authorization: Basic dXNlcjpwdw==`.		The access token has to be used in the Bearer token for authorization in subsequent API calls (see also the information about Bearer tokens in this document). The access token returned by this request MUST NOT be provided with `basic//` prefix, but the Bearer Token sent in subsequent API calls to protected endpoints MUST be prefixed with `basic//`. The header in subsequent API calls would look as follows: `Authorization: Bearer basic//TOKEN` (replace `TOKEN` with the actual access token).		It is RECOMMENDED to implement this authentication method for non-public services only.",authenticate-basic
post,openeo,/validation,Validate a user-defined process (graph),"Validates a user-defined process without executing it. A user-defined process is	considered valid unless the `errors` array in the response contains at	least one error.		Checks whether the process graph is schematically correct and the	processes are supported by the back-end. It MUST also check the	arguments against the schema, but checking whether the arguments are	adequate in the context of data is OPTIONAL. For example, a non-existing	band name may get rejected only by a few back-ends.	The validation MUST NOT throw an error for unresolvable process parameters.		Back-ends MUST validate the process graph. Validating the corresponding	metadata is OPTIONAL.		Errors that usually occur during processing MAY NOT get reported, e.g.	if a referenced file is accessible at the time of execution.		Back-ends can either report all errors at once or stop the validation	once they found the first error. 		Please note that a validation always returns with HTTP status code 200.	Error codes in the 4xx and 5xx ranges MUST be returned only when the	general validation request is invalid (e.g. server is busy or properties	in the request body are missing), but never if an error was found during	validation of the user-defined process (e.g. an unsupported process).",validate-custom-process
post,openeo,/result,Process and download data synchronously,"Executes a user-defined process directly (synchronously) and the result will be downloaded in the format specified in the process graph. This endpoint can be used to generate small previews or test user-defined processes before starting a batch job.	Timeouts on either client- or server-side are to be expected for complex computations. Back-ends MAY send the openEO error `ProcessGraphComplexity` immediately if the computation is expected to time out. Otherwise requests MAY time-out after a certain amount of time by sending openEO error `RequestTimeout`.	A header named `OpenEO-Costs` MAY be sent with all responses, which MUST include the costs for processing and downloading the data. Additionally,  a link to a log file MAY be sent in the header.",compute-result
get,openeo,/process_graphs,List all user-defined processes,"Lists all user-defined processes (process graphs) of the	authenticated user that are stored at the back-end.		It is **strongly RECOMMENDED** to keep the response size small by	omitting larger optional values from the objects in `processes`	(e.g. the `exceptions`, `examples` and `links` properties).	To get the full metadata for a user-defined process clients MUST	request `GET /process_graphs/{process_graph_id}`.",list-custom-processes
get,openeo,/process_graphs/{process_graph_id},Full metadata for a user-defined process,"Lists all information about a user-defined process, including its process graph.",describe-custom-process
put,openeo,/process_graphs/{process_graph_id},Store a user-defined process,"Stores a provided user-defined process with process graph that can be	reused in other processes.		If a process with the specified `process_graph_id` exists, the process	is fully replaced. The id can't be changed for existing user-defined	processes. The id MUST be unique across its namespace.		Partially updating user-defined processes is not supported.		To simplify exchanging user-defined processes, the property `id` can be part of	the request body. If the values don't match, the value for `id` gets	replaced with the value from the `process_graph_id` parameter in the	path.",store-custom-process
delete,openeo,/process_graphs/{process_graph_id},Delete a user-defined process,"Deletes the data related to this user-defined process, including its process graph.		Does NOT delete jobs or services that reference this user-defined process.",delete-custom-process
get,openeo,/service_types,Supported secondary web service protocols,"Lists supported secondary web service protocols such as	[OGC WMS](http://www.opengeospatial.org/standards/wms),	[OGC WCS](http://www.opengeospatial.org/standards/wcs),	[OGC API - Features](https://www.ogc.org/standards/ogcapi-features)	or [XYZ tiles](https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames).	The response is an object of all available secondary web service protocols	with their supported configuration settings and expected process parameters.		* The configuration settings for the service SHOULD be defined upon	  creation of a service and the service will be set up accordingly.	* The process parameters SHOULD be referenced (with a `from_parameter`	  reference) in the user-defined process that is used to compute web service	  results.	  The appropriate arguments MUST be provided to the user-defined process,	  usually at runtime from the context of the web service,	  For example, a map service such as a WMS would	  need to inject the spatial extent into the user-defined process so that the	  back-end can compute the corresponding tile correctly.		To improve interoperability between back-ends common names for the	services SHOULD be used, e.g. the abbreviations used in the official	[OGC Schema Repository](http://schemas.opengis.net/) for the respective	services.		Service names MUST be accepted in a *case insensitive* manner throughout the API.",list-service-types
get,openeo,/services,List all web services,"Lists all secondary web services submitted by a user.		It is **strongly RECOMMENDED** to keep the response size small by omitting	all optional non-scalar values (i.e. arrays and objects) from objects in `services`	(i.e. the `process`, `configuration` and `attributes` properties).	To get the full metadata for a secondary web service clients MUST	request `GET /services/{service_id}`.",list-services
post,openeo,/services,Publish a new service,"Creates a new secondary web service such as a	[OGC WMS](http://www.opengeospatial.org/standards/wms),	[OGC WCS](http://www.opengeospatial.org/standards/wcs),	[OGC API - Features](https://www.ogc.org/standards/ogcapi-features)	or [XYZ tiles](https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames).		The secondary web service SHOULD process the underlying	data on demand, based on process parameters provided to the	user-defined process (through `from_parameter` references) at run-time,	for example for the spatial/temporal extent, resolution, etc.	The available process parameters are specified per	service type at `GET /service_types`.		**Note:** Costs incurred by shared secondary web services are usually	paid by the owner, but this depends on the service type and whether it	supports charging fees or not.",create-service
patch,openeo,/services/{service_id},Modify a service,"Modifies an existing secondary web service at the back-end,	but maintain the identifier. Changes can be grouped in a single request.		User have to create a new service to change the service type.",update-service
get,openeo,/services/{service_id},Full metadata for a service,Lists all information about a secondary web service.,describe-service
delete,openeo,/services/{service_id},Delete a service,"Deletes all data related to this secondary web service. Computations are stopped, computed results are deleted and access to this is not possible any more. This service won't generate additional costs.",delete-service
get,openeo,/services/{service_id}/logs,Logs for a secondary service,"Lists log entries for the secondary service, usually for debugging purposes.	Back-ends can log any information that may be relevant for a user. Users can log information during data processing using respective processes such as `inspect`.	If requested consecutively while the secondary service is enabled, it is RECOMMENDED that clients use the offset parameter to get only the entries they have not received yet.	While pagination itself is OPTIONAL, the `offset` parameter is REQUIRED to be implemented by back-ends.",debug-service
get,openeo,/jobs,List all batch jobs,Lists all batch jobs submitted by a user.		It is **strongly RECOMMENDED** to keep the response size small by	omitting all optional non-scalar values (i.e. arrays and objects) from	objects in `jobs` (i.e. the `process` property).	To get the full metadata for a job clients MUST request `GET /jobs/{job_id}`.,list-jobs
post,openeo,/jobs,Create a new batch job,Creates a new batch processing task (job) from one or more (chained)	processes at the back-end.		Processing the data doesn't start yet. The job status gets initialized	as `created` by default.,create-job
patch,openeo,/jobs/{job_id},Modify a batch job,"Modifies an existing job at the back-end, but maintains the identifier.	Changes can be grouped in a single request.		The job status does not change.		Jobs can only be modified when the job is not queued and not running.	Otherwise, requests to this endpoint MUST be rejected with openEO error	`JobLocked`.",update-job
get,openeo,/jobs/{job_id},Full metadata for a batch job,Lists all information about a submitted batch job.,describe-job
delete,openeo,/jobs/{job_id},Delete a batch job,Deletes all data related to this job. Computations are stopped and computed results are deleted. This job won't generate additional costs for processing.,delete-job
get,openeo,/jobs/{job_id}/estimate,Get an estimate for a batch job,"Calculates an estimate for a batch job. Back-ends can decide to either calculate the duration, the costs, the size or a combination of them.	Back-end providers MAY specify an expiry time for the estimate. Starting to process data afterwards MAY be charged at a higher cost. Costs do often not include download costs. Whether download costs are included or not can be indicated explicitly with the `downloads_included` flag.	The estimate SHOULD be the upper limit of the costs, but back-end are free to use the field according to their terms of service.	For some batch jobs it is not (easily) possible to estimate the costs reliably, e.g. if a UDF or ML model is part of the process. In this case, the server SHOULD return a `EstimateComplexity` error with HTTP status code 500.",estimate-job
get,openeo,/jobs/{job_id}/logs,Logs for a batch job,"Lists log entries for the batch job, usually for debugging purposes.		Back-ends can log any information that may be relevant for a user	at any stage (status) of the batch job.	Users can log information during data processing using respective	processes such as `inspect`.		If requested consecutively, it is RECOMMENDED that clients use the offset	parameter to get only the entries they have not received yet.		While pagination itself is OPTIONAL, the `offset` parameter is REQUIRED	to be implemented by back-ends.",debug-job
get,openeo,/jobs/{job_id}/results,List batch job results,"Lists signed URLs pointing to the processed files, usually after the batch job	has finished. Back-ends may also point to intermediate results after the	job has stopped due to an error or if the `partial` parameter has been set.		The response includes additional metadata. It is a valid	[STAC Item](https://github.com/radiantearth/stac-spec/tree/v1.0.0/item-spec)	(if it has spatial and temporal references included) or a valid	[STAC Collection](https://github.com/radiantearth/stac-spec/tree/v1.0.0/collection-spec)	(supported since openEO API version 1.1.0).	The assets to download are in both cases available in the property `assets`	and have the same structure. All additional metadata is not strictly required	to download the files, but are helpful for users to understand the data.		STAC Collections can either (1) add all assets as collection-level assets or	(2) link to STAC Catalogs and STAC Items with signed URLs, which will provide a full	STAC catalog structure a client has to go through. Option 2 is overall the better 	architectural choice and allows a fine-grained description of the processed data,	but it is not compliant with previous versions of the openEO API.	**To maintain backward compatibility, it is REQUIRED to still copy	all assets in the STAC catalog structure into the collection-level assets.**	This requirement is planned to be removed in openEO API version 2.0.0.	A client can enforce that the server returns a GeoJSON through content negotiation	with the media type `application/geo+json`, but the results may not contain very	meaningful metadata aside from the assets.		Clients are RECOMMENDED to store this response and all potential sub-catalogs	and items with the assets so that the downloaded data is then a self-contained	STAC catalog user could publish easily with all the data and metadata.		URL signing is a way to protect files from unauthorized access with a	key in the URL instead of HTTP header based authorization. The URL	signing key is similar to a password and its inclusion in the URL allows	to download files using simple GET requests supported by a wide range of	programs, e.g. web browsers or download managers. Back-ends are	responsible to generate the URL signing keys and to manage their	appropriate expiration. The back-end MAY indicate an expiration time by	setting the `expires` property in the reponse. Requesting this endpoint	SHOULD always return non-expired URLs. Signed URLs that were generated	for a previous request and already expired SHOULD NOT be reused,	but regenerated with new expiration time.	Signed URLs that expired MAY return the openEO error `ResultLinkExpired`.		It is **strongly recommended** to add a link with relation type `canonical`	to the STAC Item or STAC Collection (see the `links` property for details).		If processing has not finished yet and the `partial` parameter is not set to `true`	requests to this endpoint MUST be rejected with openEO error `JobNotFinished`.",list-results
post,openeo,/jobs/{job_id}/results,Start processing a batch job,"Adds a batch job to the processing queue to compute the results.		The result will be stored in the format specified in the process.	To specify the format use a process such as `save_result`.		The job status is set to `queued`, if processing doesn't start	instantly. The same applies if the job status is `canceled`, `finished`,	or `error`, which restarts the job and discards previous results if the	back-end doesn't reject the request with an error.	Clients SHOULD warn users and ask for confirmation if results may get	discarded.		* Once the processing starts the status is set to `running`.	* Once the data is available to download the status is set to	`finished`.	* Whenever an error occurs during processing, the status MUST be set to	`error`.		This endpoint has no effect if the job status is already `queued` or	`running`. In particular, it doesn't restart a running job. To restart	a queued or running job, processing MUST have been canceled before.		Back-ends SHOULD reject queueing jobs with openEO error `PaymentRequired`,	if the back-end is able to detect that the budget is too low to fully	process the request. Alternatively, back-ends MAY provide partial results	once reaching the budget. If none of the alternatives is feasible, the	results are discarded. Thus, client SHOULD warn users that reaching the	budget may lead to partial or no results at all.",start-job
delete,openeo,/jobs/{job_id}/results,Cancel processing a batch job,Cancels all related computations for this job at the back-end. It will	stop generating additional costs for processing.		A subset of processed results may be available for downloading depending	on the state of the job at the time it was canceled.		Results MUST NOT be deleted until the job processing is started again or	the job is completely deleted through a request to	`DELETE /jobs/{job_id}`.		This endpoint only has an effect if the job status is `queued` or	`running`.		The job status is set to `canceled` if the status was `running`	beforehand and partial or preliminary results are available to be	downloaded. Otherwise the status is set to `created`. ,stop-job
get,openeo,/files,List all files in the workspace,Lists all user-uploaded files that are stored at the back-end.,list-files
get,openeo,/files/{path},Download a file from the workspace,Offers a file from the user workspace for download. The file is identified by its path relative to the user's root directory.	If a folder is specified as path a `FileOperationUnsupported` error MUST be sent as response.,download-file
put,openeo,/files/{path},Upload a file to the workspace,Uploads a new file to the given path or updates an existing file if a file at the path exists.		Folders are created once required by a file upload. Empty folders can't be created.,upload-file
delete,openeo,/files/{path},Delete a file from the workspace,Deletes an existing user-uploaded file specified by its path. Resulting empty folders MUST be deleted automatically.		Back-ends MAY support deleting folders including its files and sub-folders. If not supported by the back-end a `FileOperationUnsupported` error MUST be sent as response.,delete-file
get,openeo,/me,Information about the authenticated user,"Lists information about the authenticated user, e.g. the user id.	The endpoint MAY return the disk quota available to the user. The endpoint MAY also return links related to user management and the user profile, e.g. where payments are handled or the user profile could be edited.	For back-ends that involve accounting, this service MAY also return the currently available money or credits in the currency the back-end is working with.	This endpoint MAY be extended to fulfil the specification of the [OpenID Connect UserInfo Endpoint](http://openid.net/specs/openid-connect-core-1_0.html#UserInfo).",describe-account
